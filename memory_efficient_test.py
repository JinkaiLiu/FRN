#!/usr/bin/env python3
import os
import sys
import time
import numpy as np
import torch
import h5py
import hdf5plugin
import cv2

sys.path.append('.')

def test_memory_efficient_loading():
    """æµ‹è¯•å†…å­˜é«˜æ•ˆçš„äº‹ä»¶æ•°æ®åŠ è½½"""
    print("Testing memory-efficient event loading...")
    print("="*50)
    
    # ä½¿ç”¨è¾ƒå°çš„æ–‡ä»¶è¿›è¡Œæµ‹è¯•
    dataset_root = "/media/data/hucao/zhenwu/hucao/DSEC/DSEC_Det"
    events_file = os.path.join(dataset_root, "train", "interlaken_00_g", "events", "left", "events_2x.h5")
    image_file = os.path.join(dataset_root, "train", "interlaken_00_g", "images", "left", "rectified", "000000.png")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªæ—¶é—´æˆ³
    timestamp = 52107500015
    dt = 50  # 50msæ—¶é—´çª—å£
    dt_us = dt * 1000
    start_time = timestamp - dt_us
    end_time = timestamp
    
    print(f"Events file: {events_file}")
    print(f"Target timestamp: {timestamp}")
    print(f"Time window: {start_time} to {end_time}")
    
    try:
        # ç¬¬ä¸€æ­¥ï¼šæµ‹è¯•RGBå›¾åƒåŠ è½½
        print("\n1. Testing RGB image loading...")
        img = cv2.imread(image_file)
        if img is None:
            print("âŒ Failed to load RGB image")
            return False
        
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img = cv2.resize(img, (640, 480))
        img = img.astype(np.float32) / 255.0
        print(f"âœ… RGB image loaded: {img.shape}")
        
        # ç¬¬äºŒæ­¥ï¼šæµ‹è¯•äº‹ä»¶æ•°æ®åŠ è½½ï¼ˆå†…å­˜é«˜æ•ˆç‰ˆæœ¬ï¼‰
        print("\n2. Testing memory-efficient event loading...")
        start_time_load = time.time()
        
        with h5py.File(events_file, 'r') as f:
            # è·å–æ•°æ®é›†å¼•ç”¨ï¼ˆä¸åŠ è½½æ•°æ®ï¼‰
            events_t_dataset = f['events/t']
            events_x_dataset = f['events/x']
            events_y_dataset = f['events/y']
            events_p_dataset = f['events/p']
            
            total_events = events_t_dataset.shape[0]
            print(f"Total events in file: {total_events:,}")
            
            # åˆ†å—æŸ¥æ‰¾æ—¶é—´çª—å£å†…çš„äº‹ä»¶
            chunk_size = 1000000  # 100ä¸‡äº‹ä»¶ä¸€å—
            found_events = {'t': [], 'x': [], 'y': [], 'p': []}
            
            print("Searching for events in time window...")
            
            for i in range(0, total_events, chunk_size):
                end_idx = min(i + chunk_size, total_events)
                
                # åªè¯»å–æ—¶é—´æˆ³æ¥è¿‡æ»¤
                chunk_t = events_t_dataset[i:end_idx]
                
                # å¤„ç†æ—¶é—´åç§»ï¼ˆå¦‚æœæœ‰ï¼‰
                if 't_offset' in f:
                    t_offset = f['t_offset'][()]
                    chunk_t = chunk_t + t_offset
                
                # æ‰¾åˆ°æ—¶é—´çª—å£å†…çš„äº‹ä»¶
                mask = (chunk_t >= start_time) & (chunk_t < end_time)
                
                if np.any(mask):
                    # åªæœ‰æ‰¾åˆ°äº‹ä»¶æ‰è¯»å–å…¶ä»–æ•°æ®
                    chunk_x = events_x_dataset[i:end_idx][mask]
                    chunk_y = events_y_dataset[i:end_idx][mask]
                    chunk_p = events_p_dataset[i:end_idx][mask]
                    chunk_t_filtered = chunk_t[mask]
                    
                    found_events['t'].extend(chunk_t_filtered)
                    found_events['x'].extend(chunk_x)
                    found_events['y'].extend(chunk_y)
                    found_events['p'].extend(chunk_p)
                
                # è¿›åº¦æ›´æ–°
                if (i // chunk_size) % 10 == 0:
                    progress = (end_idx / total_events) * 100
                    print(f"  Progress: {progress:.1f}% - Found {len(found_events['t'])} events so far")
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        if found_events['t']:
            t = np.array(found_events['t'])
            x = np.array(found_events['x'])
            y = np.array(found_events['y'])
            p = np.array(found_events['p'])
            
            print(f"âœ… Found {len(t)} events in time window")
            
            # ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºäº‹ä»¶å›¾åƒ
            print("\n3. Creating event representation...")
            event_img = create_time_surface(x, y, t, p, 480, 640)
            print(f"âœ… Event image created: {event_img.shape}")
            print(f"Event range: [{event_img.min():.3f}, {event_img.max():.3f}]")
            
        else:
            print("âš ï¸  No events found in time window, creating empty representation")
            event_img = torch.zeros(2, 480, 640)
        
        elapsed = time.time() - start_time_load
        print(f"\nâœ… Total loading time: {elapsed:.2f} seconds")
        
        # ç¬¬å››æ­¥ï¼šæµ‹è¯•å®Œæ•´æ ·æœ¬
        print("\n4. Testing complete sample...")
        sample = {
            'img': event_img,
            'img_rgb': torch.from_numpy(img),
            'annot': torch.zeros(0, 5),  # ç©ºæ ‡æ³¨ç”¨äºæµ‹è¯•
            'sequence': 'interlaken_00_g',
            'timestamp': timestamp,
            'image_index': 0
        }
        
        print(f"âœ… Complete sample created:")
        print(f"   Event shape: {sample['img'].shape}")
        print(f"   RGB shape: {sample['img_rgb'].shape}")
        print(f"   Annotations: {sample['annot'].shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error in memory-efficient loading: {e}")
        import traceback
        traceback.print_exc()
        return False

def create_time_surface(x, y, t, p, height, width):
    """åˆ›å»ºæ—¶é—´è¡¨é¢è¡¨ç¤º"""
    time_surface = np.zeros((2, height, width), dtype=np.float32)
    
    if len(x) > 0:
        # å½’ä¸€åŒ–æ—¶é—´æˆ³
        t_normalized = (t - t.min()) / (t.max() - t.min() + 1e-6)
        
        # è¿‡æ»¤æœ‰æ•ˆåƒç´ åæ ‡
        valid_mask = (x >= 0) & (x < width) & (y >= 0) & (y < height)
        x_valid = x[valid_mask]
        y_valid = y[valid_mask]
        t_valid = t_normalized[valid_mask]
        p_valid = p[valid_mask]
        
        # å¡«å……æ—¶é—´è¡¨é¢
        for i in range(len(x_valid)):
            polarity_idx = 1 if p_valid[i] > 0 else 0
            time_surface[polarity_idx, y_valid[i], x_valid[i]] = t_valid[i]
    
    # å½’ä¸€åŒ–åˆ°[-1, 1]
    time_surface = time_surface * 2.0 - 1.0
    
    return torch.from_numpy(time_surface.copy()).float()

def test_batch_loading():
    """æµ‹è¯•æ‰¹é‡åŠ è½½å¤šä¸ªæ ·æœ¬"""
    print("\n" + "="*50)
    print("Testing batch loading with memory efficiency...")
    
    try:
        from retinanet.dataloader_dsec_det import create_dsec_det_dataloader
        
        # åˆ›å»ºåªæœ‰å°‘é‡æ ·æœ¬çš„æ•°æ®åŠ è½½å™¨
        loader, dataset = create_dsec_det_dataloader(
            root_dir="/media/data/hucao/zhenwu/hucao/DSEC/DSEC_Det",
            split='train',
            batch_size=2,
            num_workers=0,
            event_representation='time_surface',
            dt=50,
            use_downsampled_events=True,  # ä½¿ç”¨è¾ƒå°çš„æ–‡ä»¶
            normalize_images=False,
            augment=False
        )
        
        print(f"Dataset size: {len(dataset)}")
        
        # é™åˆ¶æµ‹è¯•èŒƒå›´ - åªæµ‹è¯•å‰å‡ ä¸ªæ ·æœ¬
        print("\nTesting individual samples...")
        
        # ä»è¾ƒå°çš„åºåˆ—å¼€å§‹æµ‹è¯•
        for i in range(min(3, len(dataset))):
            sample_info = dataset.samples[i]
            if 'interlaken_00_g' in sample_info['sequence'] or 'zurich_city_02_a' in sample_info['sequence']:
                print(f"\nLoading sample {i} from {sample_info['sequence']}...")
                start_time = time.time()
                
                try:
                    sample = dataset[i]
                    elapsed = time.time() - start_time
                    print(f"âœ… Sample {i} loaded in {elapsed:.2f}s")
                    print(f"   Events: {sample['img'].shape}")
                    print(f"   RGB: {sample['img_rgb'].shape}")
                    
                    if elapsed > 30:  # å¦‚æœè¶…è¿‡30ç§’å°±åœæ­¢
                        print("âš ï¸  Loading too slow, stopping test")
                        break
                        
                except Exception as e:
                    print(f"âŒ Sample {i} failed: {e}")
                    break
            else:
                print(f"Skipping sample {i} from large sequence {sample_info['sequence']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Batch loading test failed: {e}")
        return False

if __name__ == "__main__":
    print("DSEC Memory-Efficient Loading Test")
    print("="*50)
    
    # æµ‹è¯•1: å†…å­˜é«˜æ•ˆçš„å•æ ·æœ¬åŠ è½½
    success1 = test_memory_efficient_loading()
    
    if success1:
        # æµ‹è¯•2: æ‰¹é‡åŠ è½½
        success2 = test_batch_loading()
        
        if success2:
            print("\nğŸ‰ All tests passed! Memory-efficient loading works.")
            print("\nNext steps:")
            print("1. Implement this approach in your main dataloader")
            print("2. Use smaller batch sizes initially")
            print("3. Consider using only downsampled events for faster training")
        else:
            print("\nâš ï¸  Memory-efficient loading works, but batch loading needs optimization")
    else:
        print("\nâŒ Memory-efficient loading failed, need to debug further")
